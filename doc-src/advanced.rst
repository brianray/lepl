
Advanced Use
============


.. index:: Configuration(), configuration, flatten
.. _configuration:

Configuration
-------------

The configuration is used when generating a parser from the matchers graph.
It is specified using `Configuration()
<api/redirect.html#lepl.parser.Configuration>`_ which takes two arguments,
``rewriters`` and ``monitors``.

Most examples here use the default configuration, which is supplied by
`default_config()
<api/redirect.html#lepl.matchers.BaseMatcher.default_config>`_.  This is
currently defined as::

  Configuration(
    rewriters=[flatten({And: '*matchers', Or: '*matchers'})],
    monitors=[TraceResults(False), GeneratorManager(0)])

The single rewriter (`flatten() <api/redirect.html#lepl.parser.flatten>`_ ---
a function that takes a matcher graph as a single argument and returns a new,
rewritten graph as the result) rewrites nested `And()
<api/redirect.html#lepl.matchers.And>`_ and `Or()
<api/redirect.html#lepl.matchers.Or>`_ matchers.  This is a largely cosmetic
fix; without it, using repeated ``&`` and ``|`` gives an unbalanced tree of
matchers because it generates a set of nested pairs rather than a single
matcher with many sub--matchers.

The two monitors (which are passed to `trampoline()
<api/redirect.html#lepl.parser.trampoline>`_) enable the `Trace()
<api/redirect.html#lepl.matchers.Trace>`_ and `Commit()
<api/redirect.html#lepl.matchers.Commit>`_ matchers.


.. index:: search, backtracking
.. _backtracking:

Search and Backtracking
-----------------------

Since LEPL supports full backtracking via generators it is possible to request
all the alternative parses for a given input::

  >>> from lepl import *

  >>> any = Any()[:,...]
  >>> split = any & any & Eos()
  >>> match = split.match_string()

  >>> [pair[0] for pair in match('****')]
  [['****'], ['***', '*'], ['**', '**'], ['*', '***'], ['****']]

This shows that successive parses match less of the input with the first
option, indicating that the matching is *greedy*.

*Non-greedy* (generous?) matching is achieved by specifying an array slice
increment of ``'b'`` (or `BREADTH_FIRST
<api/redirect.html#lepl.matchers.BREADTH_FIRST>`_)::

  >>> any = Any()[::'b',...]
  >>> split = any & any & Eos()
  >>> match = split.match_string()

  >>> [pair for (pair, stream) in match('****')]
  [['****'], ['*', '***'], ['**', '**'], ['***', '*'], ['****']]

The greedy and non--greedy repetitions are implemented by depth (default,
``'d'``, or `DEPTH_FIRST <api/redirect.html#lepl.matchers.DEPTH_FIRST>`_),
and breadth--first searches (``'b'`` or `BREADTH_FIRST
<api/redirect.html#lepl.matchers.BREADTH_FIRST>`_), respectively.

In addition, by specifying a slice increment of ``'g'`` (`GREEDY
<api/redirect.html#lepl.matchers.GREEDY>`_), you can request a *guaranteed
greedy* match.  This evaluates all possibilities, before returning them in
reverse length order.  Typically this will be identical to depth--first
search, but it is possible for backtracking to produce a longer match in
complex cases --- this final option, by evaluating all cases, re--orders the
results as necessary.

Specifying ``'n'`` (`NON_GREEDY
<api/redirect.html#lepl.matchers.NON_GREEDY>`_) gets the reverse ordering.

The tree implicit in the descriptions "breadth--first" and "depth--first" is
not the AST, nor the tree of matchers, but a tree based on matchers and
streams.  In the case of a single, repeated, match this is easy to visualise:
at any particular node the child nodes are generated by applying the matcher
to the various streams returned by the current match (none if this is a final
node, one for a simple match, several if the matcher backtracks).

So far so good.  Unfortunately the process is more complicated for `And()
<api/redirect.html#lepl.matchers.And>`_ and `Or()
<api/redirect.html#lepl.matchers.Or>`_.

In the case of `And() <api/redirect.html#lepl.matchers.And>`_, the first
matcher is matched first.  The child nodes correspond to the various (with
backtracking) results of this match.  At each child node, the second matcher
is applied, generating new children.  This repeats until the scope of the
`And() <api/redirect.html#lepl.matchers.And>`_ terminates at a depth in the
tree corresponding to the children of the last matcher.  Since `And()
<api/redirect.html#lepl.matchers.And>`_ fails unless all matchers match, only
the final child nodes are possible results.  As a consequence, both breadth
and depth first searches would return the same ordering.  The `And()
<api/redirect.html#lepl.matchers.And>`_ match is therefore unambiguous and the
implementation has no way to specify the (essentially meaningless) choice
between the two searches.

In the case of `Or() <api/redirect.html#lepl.matchers.Or>`_ we must select
both the matcher and the result from the results available for that matcher.
A natural approach is to assign the first generation of children to the choice
of matcher, and the second level to the choice of result for the (parent)
matcher.  Again, this results in no ambiguity between breadth and depth--first
results.

However, there is also an intuitively attractive argument that breadth--first
search would return the first results of the different matches, in series,
before considering backtracking.  At the moment I do not see a "natural" way
to form such a tree, and so this is not implemented.  Feedback is appreciated.


.. index:: memoisation, RMemo(), LMemo(), memoize(), ambiguous grammars, left-recursion
.. _memoisation:

Memoisation
-----------

LEPL 2.0 supports two approaches to memoisation.

The simplest memoizer is `RMemo() <api/redirect.html#lepl.memo.RMemo>`_ which is
a cache based on the stream supplied.

For left--recursive grammars, however, things are more complicated (for full
details see :ref:`memoisation`).  In this case, `LMemo()
<api/redirect.html#lepl.memo.LMemo>`_ must be used.

Memoizers can either be specified directly, as matchers in the grammar, or via
the :ref:`configuration`.  If they are used directly they only affect the
matcher to which they are applied.  If they are given as a rewriter in the
configuration then they are automatically applied to every matcher.

First, an example of restricted use::

  >>> matcher = Any('a')[:] & Any('a')[:] & RMemo(Any('b')[4])
  >>> len(list(matcher.match('aaaabbbb')))
  5

Here the `RMemo() <api/redirect.html#lepl.memo.RMemo>`_ avoids re-matching of
the "bbbb" for each different combination of "a"s.
    
Next, an example where the memoizer is added to all matchers via rewriting of
the matcher graph (from the paper describing the technique used for handling
left--recursive grammars)::
        
  >>> class VerbPhrase(Node): pass
  >>> class DetPhrase(Node): pass
  >>> class SimpleTp(Node): pass
  >>> class TermPhrase(Node): pass
  >>> class Sentence(Node): pass

  >>> verb        = Literals('knows', 'respects', 'loves')         > 'verb'
  >>> join        = Literals('and', 'or')                          > 'join'
  >>> proper_noun = Literals('helen', 'john', 'pat')               > 'proper_noun'
  >>> determiner  = Literals('every', 'some')                      > 'determiner'
  >>> noun        = Literals('boy', 'girl', 'man', 'woman')        > 'noun'
        
  >>> verbphrase  = Delayed()
  >>> verbphrase += verb | (verbphrase // join // verbphrase)      > VerbPhrase
  >>> det_phrase  = determiner // noun                             > DetPhrase
  >>> simple_tp   = proper_noun | det_phrase                       > SimpleTp
  >>> termphrase  = Delayed()
  >>> termphrase += simple_tp | (termphrase // join // termphrase) > TermPhrase
  >>> sentence    = termphrase // verbphrase // termphrase & Eos() > Sentence
    
  >>> p = sentence.null_matcher(
  >>>         Configuration(rewriters=[memoize(LMemo)], 
  >>>                       monitors=[TraceResults(False)]))
  >>> len(list(p('every boy or some girl and helen and john or pat knows '
  >>>            'and respects or loves every boy or some girl and pat or '
  >>>            'john and helen')))
  392

This example is left--recursive and very ambiguous.  With `LMemo()
<api/redirect.html#lepl.memo.LMemo>`_ it can be parsed with no problems.

The `memoize() <api/redirect.html#lepl.parser.memoize>`_ function converts a
memoizing matcher to a rewriter.

.. note::

  In both cases above there is nothing obvious to show that the memoizer is
  actually used (I am just printing the number of different parses available).
  Efficiency and profiling will be addressed in the next release.
