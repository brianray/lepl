
Closing Remarks
===============

This chapter contains various observations, comments, etc, that didn't fit
elsewhere in the documentation.


Supported Versions
------------------

The code was written using Python 3.0.  It was then backported to Python 2.6
and appears to work fine there (except that the ``//`` operator doesn't
exist).  It might even work with Python 2.5 if you add appropriate ``from
__future__ import ...`` in various places (you could make the ``Matcher`` ABC
a simple class without really harming anything).

However, it's not regularly tested on anything other than 3.0...


Licence
-------

Licensed under the Lesser Gnu Public Licence.  Copyright 2009 Andrew Cooke
(andrew@acooke.org).


Technical Summary
-----------------

.. index:: recursive descent, generators, stack, parser combinators

In the chapters above I have tried to explain LEPL without mentioning any
"theoretical" details.  Now I am going to jump ahead and give a short,
technical description that requires a lot more background knowledge.  The aim
here is to show experts how the system is implemented; you do not need to
understand this section to use LEPL.

LEPL is, at heart, a recursive descent parser.  It owes much to standard
parser combinator libraries in functional languages.  For example, each
matcher takes a stream as an argument and, on success, returns a tuple
containing a list of matches and a new stream.  

However, LEPL also exploits Python in two ways.  First, it overloads operators
to provide a large helping of syntactic sugar (operators simply apply more
combinators, so ``a | b`` is equivalent to ``Or(a, b)``).  Second, generators
are used to manage backtracking.

Consistent use of generators means that the entire parser can backtrack
(typically recursive descent parsing restricts backtracking to ``Or(...)``).
It also reduces the use of the C stack (naturally replacing recursion with
iteration) and allows the environmental cost of backtracking to be managed
(generators can be tracked and closed, effectively reclaiming resources on the
"stack"; the same mechanism can implement "cut").


.. _backtracking:

Search and Backtracking
-----------------------

Since LEPL supports full backtracking via generators it is possible to request
all the alternative parses for a given input::

  >>> from lepl import *

  >>> any = Any()[:,...]
  >>> split = any & any & Eos()
  >>> match = split.match_string()

  >>> [pair[0] for pair in match('****')]
  [['****'], ['***', '*'], ['**', '**'], ['*', '***'], ['****']]

This shows that successive parses match less of the input with the first
option, indicating that the matching is *greedy*.

*Non-greedy* (generous?) matching is achieved by specifying an array slice
increment of ``'b'`` (or ``lepl.BREADTH_FIRST``)::

  >>> any = Any()[::'b',...]
  >>> split = any & any & Eos()
  >>> match = split.match_string()

  >>> [pair for (pair, stream) in match('****')]
  [['****'], ['*', '***'], ['**', '**'], ['***', '*'], ['****']]

The greedy and non--greedy repetitions are implemented by depth (default,
``'d'``, or ``lepl.DEPTH_FIRST``), and breadth--first searches (``'b'`` or
``lepl.BREADTH_FIRST``), respectively.

In addition, by specifying a slice increment of ``'g'`` (``LEPL.GREEDY``), you
can request a *guaranteed greedy* match.  This evaluates all possibilities,
before returning them in reverse length order.  Typically this will be
identical to depth--first search, but it is possible for backtracking to
produce a longer match in complex cases --- this final option, by evaluating
all cases, re--orders the results as necessary.

Specifying ``'n'`` (``lepl.NON_GREEDY``) gets the reverse ordering.

The tree implicit in the descriptions "breadth--first" and "depth--first" is
not the AST, nor the tree of matchers, but a tree based on matchers and
streams.  In the case of a single, repeated, match this is easy to visualise:
at any particular node the child nodes are generated by applying the matcher
to the various streams returned by the current match (none if this is a final
node, one for a simple match, several if the matcher backtracks).

So far so good.  Unfortunately the process is more complicated for ``And()``
and ``Or()``.

In the case of ``And()``, the first matcher is matched first.  The child nodes
correspond to the various (with backtracking) results of this match.  At each
child node, the second matcher is applied, generating new children.  This
repeats until the scope of the ``And()`` terminates at a depth in the tree
corresponding to the children of the last matcher.  Since ``And()`` fails
unless all matchers match, only the final child nodes are possible results.
As a consequence, both breadth and depth first searches would return the same
ordering.  The ``And()`` match is therefore unambiguous and the implementation
has no way to specify the (essentially meaningless) choice between the two
searches.

In the case of ``Or()`` we must select both the matcher and the result from
the results available for that matcher.  A natural approach is to assign the
first generation of children to the choice of matcher, and the second level to
the choice of result for the (parent) matcher.  Again, this results in no
ambiguity betwen breadth and depth--first results.

However, there is also an intuitively attractive argument that breadth--first
search would return the first results of the different matches, in series,
before considering backtracking.  At the moment I do not see a "natural" way
to form such a tree, and so this is not implemented.  Feedback is appreciated.


Credits
-------

.. index:: Tim Peters, Sam Wilmott, Pattern Matching in Python, Guy Cousineau,
           Michel Mauny, PyParsing, Paul McGuire

Blame Tim Peters' `test_generators.py
<http://www.koders.com/python/fid9B99238B5452E1EDA851459C2F4B5FD19ECBAD17.aspx?s=mdef%3Amd5>`_
for starting me thinking about this, but that would have got nowhere without Sam
Wilmott's `Pattern Matching in Python
<http://www.wilmott.ca/python/patternmatching.html>`_ from which I have
stolen almost everything (including the repetition syntax).

`PyParsing <http://pyparsing.wikispaces.com/>`_ was also a major motivation
(if you don't like the way LEPL handles spaces, you may prefer Paul McGuire's
package which is, I think, pretty much the standard for simple, recursive
descent Python parsers).

Finally, thanks to `Guy Cousineau and Michel Mauny
<http://books.google.cl/books?hl=en&id=-vQPDXciXUMC&dq=cousineau+mauny>`_ for
the original education.



Endnote
-------

LEPL was written as Israel largely destroyed Gaza.
