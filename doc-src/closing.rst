
Closing Remarks
===============

This chapter contains various observations, comments, etc, that didn't fit
elsewhere in the documentation.


.. index:: recursive descent, generators, stack, parser combinators

Technical Summary
-----------------

In the chapters above I have tried to explain LEPL without mentioning any
"theoretical" details.  Now I am going to jump ahead and give a short,
technical description that requires a lot more background knowledge.  The aim
here is to show experts how the system is implemented; you do not need to
understand this section to use LEPL.

LEPL is, at heart, a recursive descent parser.  It owes much to standard
parser combinator libraries in functional languages.  For example, each
matcher takes a stream as an argument and, on success, returns a tuple
containing a list of matches and a new stream.  

However, LEPL also exploits Python in two ways.  First, it overloads operators
to provide a large helping of syntactic sugar (operators simply apply more
combinators, so ``a | b`` is equivalent to `Or(a, b)
<api/redirect.html#lepl.match.Or>`_).  Second, generators are used to
manage backtracking.

Consistent use of generators means that the entire parser can backtrack
(typically recursive descent parsing restricts backtracking to `Or(...)
<api/redirect.html#lepl.match.Or>`_).  It also reduces the use of the C
stack (naturally replacing recursion with iteration) and allows the
environmental cost of backtracking to be managed (generators can be tracked
and closed, effectively reclaiming resources on the "stack"; the same
mechanism can implement "cut").


.. _backtracking:

Search and Backtracking
-----------------------

Since LEPL supports full backtracking via generators it is possible to request
all the alternative parses for a given input::

  >>> from lepl import *

  >>> any = Any()[:,...]
  >>> split = any & any & Eos()
  >>> match = split.match_string()

  >>> [pair[0] for pair in match('****')]
  [['****'], ['***', '*'], ['**', '**'], ['*', '***'], ['****']]

This shows that successive parses match less of the input with the first
option, indicating that the matching is *greedy*.

*Non-greedy* (generous?) matching is achieved by specifying an array slice
increment of ``'b'`` (or `BREADTH_FIRST
<api/redirect.html#lepl.match.BREADTH_FIRST>`_)::

  >>> any = Any()[::'b',...]
  >>> split = any & any & Eos()
  >>> match = split.match_string()

  >>> [pair for (pair, stream) in match('****')]
  [['****'], ['*', '***'], ['**', '**'], ['***', '*'], ['****']]

The greedy and non--greedy repetitions are implemented by depth (default,
``'d'``, or `DEPTH_FIRST <api/redirect.html#lepl.match.BDEPTH_FIRST>`_),
and breadth--first searches (``'b'`` or `BREADTH_FIRST
<api/redirect.html#lepl.match.BREADTH_FIRST>`_), respectively.

In addition, by specifying a slice increment of ``'g'`` (`GREEDY
<api/redirect.html#lepl.match.GREEDY>`_), you can request a *guaranteed
greedy* match.  This evaluates all possibilities, before returning them in
reverse length order.  Typically this will be identical to depth--first
search, but it is possible for backtracking to produce a longer match in
complex cases --- this final option, by evaluating all cases, re--orders the
results as necessary.

Specifying ``'n'`` (`NON_GREEDY
<api/redirect.html#lepl.match.NON_GREEDY>`_) gets the reverse ordering.

The tree implicit in the descriptions "breadth--first" and "depth--first" is
not the AST, nor the tree of matchers, but a tree based on matchers and
streams.  In the case of a single, repeated, match this is easy to visualise:
at any particular node the child nodes are generated by applying the matcher
to the various streams returned by the current match (none if this is a final
node, one for a simple match, several if the matcher backtracks).

So far so good.  Unfortunately the process is more complicated for `And()
<api/redirect.html#lepl.match.And>`_ and `Or()
<api/redirect.html#lepl.match.Or>`_.

In the case of `And() <api/redirect.html#lepl.match.And>`_, the first
matcher is matched first.  The child nodes correspond to the various (with
backtracking) results of this match.  At each child node, the second matcher
is applied, generating new children.  This repeats until the scope of the
`And() <api/redirect.html#lepl.match.And>`_ terminates at a depth in the
tree corresponding to the children of the last matcher.  Since `And()
<api/redirect.html#lepl.match.And>`_ fails unless all matchers match, only
the final child nodes are possible results.  As a consequence, both breadth
and depth first searches would return the same ordering.  The `And()
<api/redirect.html#lepl.match.And>`_ match is therefore unambiguous and the
implementation has no way to specify the (essentially meaningless) choice
between the two searches.

In the case of `Or() <api/redirect.html#lepl.match.Or>`_ we must select
both the matcher and the result from the results available for that matcher.
A natural approach is to assign the first generation of children to the choice
of matcher, and the second level to the choice of result for the (parent)
matcher.  Again, this results in no ambiguity betwen breadth and depth--first
results.

However, there is also an intuitively attractive argument that breadth--first
search would return the first results of the different matches, in series,
before considering backtracking.  At the moment I do not see a "natural" way
to form such a tree, and so this is not implemented.  Feedback is appreciated.


.. index:: Tim Peters, Sam Wilmott, Pattern Matching in Python, Guy Cousineau,
           Michel Mauny, PyParsing, Paul McGuire

Credits
-------

Blame Tim Peters' `test_generators.py
<http://www.koders.com/python/fid9B99238B5452E1EDA851459C2F4B5FD19ECBAD17.aspx?s=mdef%3Amd5>`_
for starting me thinking about this, but that would have got nowhere without Sam
Wilmott's `Pattern Matching in Python
<http://www.wilmott.ca/python/patternmatching.html>`_ from which I have
stolen almost everything (including the repetition syntax).

`PyParsing <http://pyparsing.wikispaces.com/>`_ was also a major motivation
(if you don't like the way LEPL handles spaces, you may prefer Paul McGuire's
package which is, I think, pretty much the standard for simple, recursive
descent Python parsers).

Finally, thanks to `Guy Cousineau and Michel Mauny
<http://books.google.cl/books?hl=en&id=-vQPDXciXUMC&dq=cousineau+mauny>`_ for
the original education.


.. index:: futile despair

Endnote
-------

LEPL was written as Israel, with the implicit support of the USA, largely
destroyed Gaza.
